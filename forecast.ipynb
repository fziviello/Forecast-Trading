{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create DataSet using symbol AUDJPY"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Start Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "import schedule\n",
    "import logging\n",
    "import time\n",
    "from datetime import datetime\n",
    "\n",
    "SCRIPT_CREATE_DATASET = \"create_dataSet.py\"\n",
    "SCRIPT_FORECAST = \"forecast_bot.py\"\n",
    "LOG_FILE_PATH = 'scheduler.log'\n",
    "TIME_MINUTE_REPEAT = 30\n",
    "N_REPEAT = 5\n",
    "\n",
    "logging.basicConfig(filename=LOG_FILE_PATH, level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "    \n",
    "def run_scripts(SCRIPT_CREATE_DATASET, SCRIPT_FORECAST):\n",
    "    print(f\"\\033[93m*** Avvio Creazione del DataSet\\033[0m\\n\")\n",
    "    process1 = subprocess.Popen(\n",
    "        [\"python\", SCRIPT_CREATE_DATASET],\n",
    "        stdout=subprocess.PIPE,\n",
    "        stderr=subprocess.PIPE,\n",
    "        bufsize=1,\n",
    "        text=True\n",
    "    )\n",
    "\n",
    "    for line in process1.stdout:\n",
    "        print(line, end='', flush=True)\n",
    "    for line in process1.stderr:\n",
    "        logging.error(line.strip())\n",
    "\n",
    "    process1.stdout.close()\n",
    "    process1.stderr.close()\n",
    "    process1.wait()\n",
    "\n",
    "    print(f\"\\n\\033[93m*** Avvio Forecast\\033[0m\\n\")\n",
    "    process2 = subprocess.Popen(\n",
    "        [\"python\", SCRIPT_FORECAST],\n",
    "        stdout=subprocess.PIPE,\n",
    "        stderr=subprocess.PIPE,\n",
    "        bufsize=1,\n",
    "        text=True\n",
    "    )\n",
    "\n",
    "    for line in process2.stdout:\n",
    "        print(line, end='', flush=True)\n",
    "    for line in process2.stderr:\n",
    "        logging.error(line.strip())\n",
    "\n",
    "    process2.stdout.close()\n",
    "    process2.stderr.close()\n",
    "    process2.wait()\n",
    "\n",
    "def schedule_scripts(SCRIPT_CREATE_DATASET, SCRIPT_FORECAST, N_REPEAT):\n",
    "    executions = {'count': 0}\n",
    "\n",
    "    def job():\n",
    "        print(f\"\\033[96mESECUZIONE {executions['count']+1}\\033[0m\\n\")\n",
    "        if executions['count'] < N_REPEAT:\n",
    "            run_scripts(SCRIPT_CREATE_DATASET, SCRIPT_FORECAST)\n",
    "            executions['count'] += 1\n",
    "        else:\n",
    "            print(\"Esecuzioni Programmate Terminate\")\n",
    "            return schedule.CancelJob\n",
    "    job()\n",
    "\n",
    "    schedule.every(TIME_MINUTE_REPEAT).minutes.do(job)\n",
    "\n",
    "    while executions['count'] < N_REPEAT:\n",
    "        schedule.run_pending()\n",
    "        time.sleep(1)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    now = datetime.now()\n",
    "    print(f'\\033[96mTrainer Avviato il {now.strftime(\"%Y-%m-%d %H:%M:%S\")} per {N_REPEAT} esecuzioni\\033[0m\\n')\n",
    "    schedule_scripts(SCRIPT_CREATE_DATASET, SCRIPT_FORECAST, N_REPEAT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[92mDataset generato con successo\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "import yfinance as yf\n",
    "import mplfinance as mpf\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "GENERATE_PLOT = False\n",
    "SYMBOL = 'AUDJPY=X'\n",
    "CSVNAME = 'forex_data.csv'\n",
    "PLOTNAME = 'forex_chart.png'\n",
    "INTERVAL = '30m'\n",
    "\n",
    "today = datetime.now()\n",
    "if INTERVAL == \"30m\" :\n",
    "   ndays = 60\n",
    "else:\n",
    "   ndays = 730\n",
    "\n",
    "startDate = today - timedelta(days=ndays)\n",
    "\n",
    "def getForexData(symbol):\n",
    "    try:\n",
    "        sym = yf.Ticker(symbol)\n",
    "        data = sym.history(start=startDate, end=today, interval=INTERVAL)\n",
    "        if data.empty:\n",
    "            raise ValueError(f\"Nessun dato restituito per {symbol}\")\n",
    "        \n",
    "        data.reset_index(inplace=True)\n",
    "        return data[['Datetime', 'Open', 'High', 'Low', 'Close']]\n",
    "    except Exception as e:\n",
    "        print(f\"Errore durante il recupero dei dati: {e}\")\n",
    "        return None\n",
    "\n",
    "forex_data = getForexData(SYMBOL)\n",
    "\n",
    "if forex_data is not None:\n",
    "    if GENERATE_PLOT:\n",
    "        mpf.plot(\n",
    "            forex_data.set_index('Datetime'),\n",
    "            type='candle', \n",
    "            style='charles',\n",
    "            title=f\"{SYMBOL} Forex Data\",\n",
    "            ylabel='Prezzo',\n",
    "            volume=False\n",
    "        )\n",
    "        mpf.show()\n",
    "        \n",
    "        mpf.plot(\n",
    "            forex_data.set_index('Datetime'),\n",
    "            type='candle',\n",
    "            style='charles',\n",
    "            title=f\"{SYMBOL} Forex Data\",\n",
    "            ylabel='Prezzo',\n",
    "            volume=False,\n",
    "            savefig=PLOTNAME\n",
    "        )\n",
    "        print(f\"\\033[92m{'Grafico salvato con successo in ' + PLOTNAME}\\033[0m\")\n",
    "    \n",
    "    forex_data.to_csv(CSVNAME, index=False)\n",
    "    print(f\"\\033[92m{'Dataset generato con successo'}\\033[0m\")\n",
    "else:\n",
    "    print(f\"\\033[91m{'Impossibile generare il dataset a causa di un errore nel recupero dei dati.'}\\033[0m\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-07 09:46:25.309606: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[94m\n",
      "Il tasso di cambio da AUD a EUR è: \u001b[92m0.62€\u001b[0m\n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 633ms/step\n",
      "\n",
      "Previsioni Generate:\n",
      "\n",
      " 1)  \u001b[91mSell Stop\u001b[0m Prezzo: \u001b[96m101.978\u001b[0m Stop Loss: \u001b[93m104.018\u001b[0m Take Profit: \u001b[95m101.774\u001b[0m Guadagno: \u001b[92m1.26€\u001b[0m Perdita: \u001b[91m-12.65€\u001b[0m\n",
      " 2)  \u001b[91mSell Stop\u001b[0m Prezzo: \u001b[96m101.994\u001b[0m Stop Loss: \u001b[93m104.034\u001b[0m Take Profit: \u001b[95m101.790\u001b[0m Guadagno: \u001b[92m1.26€\u001b[0m Perdita: \u001b[91m-12.65€\u001b[0m\n",
      " 3)  \u001b[91mSell Stop\u001b[0m Prezzo: \u001b[96m101.995\u001b[0m Stop Loss: \u001b[93m104.035\u001b[0m Take Profit: \u001b[95m101.791\u001b[0m Guadagno: \u001b[92m1.26€\u001b[0m Perdita: \u001b[91m-12.65€\u001b[0m\n",
      " 4)  \u001b[91mSell Stop\u001b[0m Prezzo: \u001b[96m102.000\u001b[0m Stop Loss: \u001b[93m104.040\u001b[0m Take Profit: \u001b[95m101.796\u001b[0m Guadagno: \u001b[92m1.26€\u001b[0m Perdita: \u001b[91m-12.65€\u001b[0m\n",
      " 5)  \u001b[91mSell Stop\u001b[0m Prezzo: \u001b[96m102.020\u001b[0m Stop Loss: \u001b[93m104.060\u001b[0m Take Profit: \u001b[95m101.816\u001b[0m Guadagno: \u001b[92m1.26€\u001b[0m Perdita: \u001b[91m-12.65€\u001b[0m\n",
      " 6)  \u001b[91mSell Stop\u001b[0m Prezzo: \u001b[96m102.022\u001b[0m Stop Loss: \u001b[93m104.062\u001b[0m Take Profit: \u001b[95m101.818\u001b[0m Guadagno: \u001b[92m1.26€\u001b[0m Perdita: \u001b[91m-12.65€\u001b[0m\n",
      " 7)  \u001b[91mSell Stop\u001b[0m Prezzo: \u001b[96m102.062\u001b[0m Stop Loss: \u001b[93m104.103\u001b[0m Take Profit: \u001b[95m101.858\u001b[0m Guadagno: \u001b[92m1.26€\u001b[0m Perdita: \u001b[91m-12.65€\u001b[0m\n",
      " 8)  \u001b[91mSell Stop\u001b[0m Prezzo: \u001b[96m102.076\u001b[0m Stop Loss: \u001b[93m104.118\u001b[0m Take Profit: \u001b[95m101.872\u001b[0m Guadagno: \u001b[92m1.26€\u001b[0m Perdita: \u001b[91m-12.66€\u001b[0m\n",
      " 9)  \u001b[91mSell Stop\u001b[0m Prezzo: \u001b[96m102.103\u001b[0m Stop Loss: \u001b[93m104.145\u001b[0m Take Profit: \u001b[95m101.899\u001b[0m Guadagno: \u001b[92m1.26€\u001b[0m Perdita: \u001b[91m-12.66€\u001b[0m\n",
      "10)  \u001b[91mSell Stop\u001b[0m Prezzo: \u001b[96m102.135\u001b[0m Stop Loss: \u001b[93m104.178\u001b[0m Take Profit: \u001b[95m101.931\u001b[0m Guadagno: \u001b[92m1.26€\u001b[0m Perdita: \u001b[91m-12.67€\u001b[0m\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import yfinance as yf\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from tensorflow.keras.models import Sequential, load_model\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "import joblib\n",
    "import os\n",
    "from datetime import datetime,timedelta\n",
    "import pytz\n",
    "import mplfinance as mpf\n",
    "import logging\n",
    "\n",
    "MODEL_PATH = 'lstm_trading_model.h5'\n",
    "SCALER_PATH = 'scaler.pkl'\n",
    "DATASET_PATH = 'forex_data.csv'\n",
    "FORECAST_RESULTS_PATH = 'forecast_trading.csv'\n",
    "VALIDATION_RESULTS_PATH = 'forecast_validation.csv'\n",
    "LOG_FILE_PATH = 'forecast_trading.log'\n",
    "PLOT_FILE_PATH = 'forecast_trading.png'\n",
    "\n",
    "MARGIN_PROFIT = 0.002\n",
    "LEVERAGE = 0.01\n",
    "UNIT = 1000\n",
    "EXCHANGE_RATE = 1.0\n",
    "DATA_MODEL_RATE = \"AUD\"\n",
    "FAVORITE_RATE = \"EUR\"\n",
    "N_PREDICTIONS = 10\n",
    "VALIDATION_THRESHOLD = 0.1\n",
    "\n",
    "GENERATE_PLOT = False\n",
    "OVERWRITE_FORECAST_CSV = False\n",
    "\n",
    "logging.basicConfig(filename=LOG_FILE_PATH, level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "\n",
    "def calculator_profit(predicted_take_profit, predicted_entry_price):\n",
    "    return round(abs((predicted_take_profit - predicted_entry_price) * UNIT * LEVERAGE * EXCHANGE_RATE), 2)\n",
    "            \n",
    "def calculator_loss(predicted_stop_loss, predicted_entry_price):\n",
    "    return round((predicted_entry_price - predicted_stop_loss) * UNIT * LEVERAGE * EXCHANGE_RATE, 2)\n",
    "\n",
    "def exchange_currency(base, target):\n",
    "    ticker = f\"{base}{target}=X\"\n",
    "    try:\n",
    "        data = yf.Ticker(ticker)\n",
    "        exchange_rate = (data.history(period=\"1d\")['Close'].iloc[-1])\n",
    "        exchange_rate = round(exchange_rate, 2)\n",
    "        print(f\"\\033[94m\\nIl tasso di cambio da {base} a {target} è: \\033[92m{exchange_rate}€\\033[0m\\n\")\n",
    "        logging.info(f\"Il tasso di cambio da {base} a {target} è: {exchange_rate}\")\n",
    "        return exchange_rate\n",
    "    except Exception as e:\n",
    "        print(f\"\\033[91m'Errore nel recuperare il tasso di cambio, verrà utilizzato il suo valore di default'\\033[0m\")\n",
    "        logging.error(f\"Errore nel recuperare il tasso di cambio: {e}\")\n",
    "        return None\n",
    "\n",
    "def load_and_preprocess_data():\n",
    "    df = pd.read_csv(DATASET_PATH, parse_dates=['Datetime'])\n",
    "    df.set_index('Datetime', inplace=True)\n",
    "\n",
    "    df['MA20'] = df['Close'].rolling(window=20).mean()\n",
    "    df['MA50'] = df['Close'].rolling(window=50).mean()\n",
    "    df['Volatility'] = df['Close'].rolling(window=20).std()\n",
    "    \n",
    "    delta = df['Close'].diff(1)\n",
    "    gain = (delta.where(delta > 0, 0)).rolling(window=14).mean()\n",
    "    loss = (-delta.where(delta < 0, 0)).rolling(window=14).mean()\n",
    "    df['RSI'] = 100 - (100 / (1 + gain / loss))\n",
    "\n",
    "    df['MACD'] = df['Close'].ewm(span=12, adjust=False).mean() - df['Close'].ewm(span=26, adjust=False).mean()\n",
    "    df['Signal Line'] = df['MACD'].ewm(span=9, adjust=False).mean()\n",
    "\n",
    "    df['Upper Bollinger'] = df['MA20'] + 2 * df['Volatility']\n",
    "    df['Lower Bollinger'] = df['MA20'] - 2 * df['Volatility']\n",
    "    \n",
    "    df['Target'] = np.where(df['Close'].shift(-1) > df['Close'], 1, 0)\n",
    "    df.dropna(inplace=True)\n",
    "    \n",
    "    return df\n",
    "\n",
    "def create_sequences(X, y, time_steps=30):\n",
    "    X_seq, y_seq = [], []\n",
    "    for i in range(len(X) - time_steps):\n",
    "        X_seq.append(X[i:i + time_steps])\n",
    "        y_seq.append(y[i + time_steps])\n",
    "    return np.array(X_seq), np.array(y_seq)\n",
    "\n",
    "def validate_predictions():\n",
    "    global REPEAT_TRAINING\n",
    "    if not os.path.exists(FORECAST_RESULTS_PATH):\n",
    "        logging.info(\"Nessuna previsione precedente da validare.\")\n",
    "        return\n",
    "\n",
    "    prev_predictions = pd.read_csv(FORECAST_RESULTS_PATH)\n",
    "    df = pd.read_csv(DATASET_PATH, parse_dates=['Datetime'])\n",
    "    validation_results = []\n",
    "    unsuccessful_count = 0\n",
    "\n",
    "    for i, row in prev_predictions.iterrows():\n",
    "        pred_datetime = pd.to_datetime(row['Data Previsione'])\n",
    "        actual_data = df.loc[df['Datetime'] >= pred_datetime]\n",
    "\n",
    "        if not actual_data.empty:\n",
    "            actual_close = actual_data.iloc[0]['Close']\n",
    "            predicted_entry_price = float(row['Prezzo'])\n",
    "            predicted_take_profit = float(row['Take Profit'])\n",
    "            predicted_stop_loss = float(row['Stop Loss'])\n",
    "\n",
    "            if actual_close >= predicted_take_profit:\n",
    "                result = \"Successo - Take Profit raggiunto\"\n",
    "            elif actual_close <= predicted_stop_loss:\n",
    "                result = \"Fallimento - Stop Loss raggiunto\"\n",
    "                unsuccessful_count += 1\n",
    "            else:\n",
    "                result = \"Previsione non avvenuta\"\n",
    "            \n",
    "            validation_results.append({\n",
    "                'Data Previsione': pred_datetime,\n",
    "                'Tipo': row['Tipo'],\n",
    "                'Risultato': result,\n",
    "                'Prezzo': predicted_entry_price,\n",
    "                'Close Attuale': actual_close,\n",
    "                'Take Profit': predicted_take_profit,\n",
    "                'Stop Loss': predicted_stop_loss,\n",
    "                'Guadagno': f\"{calculator_profit(predicted_take_profit, predicted_entry_price):.2f}€\",\n",
    "                'Perdita': f\"{calculator_loss(predicted_stop_loss, predicted_entry_price):.2f}€\"\n",
    "            })\n",
    "\n",
    "    if validation_results:\n",
    "        validation_df = pd.DataFrame(validation_results)\n",
    "        validation_df.to_csv(VALIDATION_RESULTS_PATH, index=False)\n",
    "        logging.info(f\"Risultati di validazione salvati in {VALIDATION_RESULTS_PATH}.\")\n",
    "\n",
    "    total_predictions = len(prev_predictions)\n",
    "    if total_predictions > 0:\n",
    "        failure_rate = unsuccessful_count / total_predictions\n",
    "        if failure_rate > 0:\n",
    "            print(f\"\\033[91mTasso di previsioni non riuscite: {failure_rate:.2f}\\033[0m\")\n",
    "        logging.info(f\"Tasso di previsioni non riuscite: {failure_rate:.2f}\")\n",
    "        REPEAT_TRAINING = failure_rate > VALIDATION_THRESHOLD\n",
    "\n",
    "def plot_forex_candlestick(df, predictions):\n",
    "    df_plot = df[-N_PREDICTIONS:].copy()\n",
    "    \n",
    "    df_plot.index = pd.to_datetime(df_plot.index)\n",
    "\n",
    "    df_plot['Date'] = df_plot.index\n",
    "    df_plot.index.name = 'Date'\n",
    "    df_plot = df_plot[['Open', 'High', 'Low', 'Close']]\n",
    "\n",
    "    buy_signals = df_plot.iloc[[i for i, x in enumerate(predictions) if x == 1]]\n",
    "    sell_signals = df_plot.iloc[[i for i, x in enumerate(predictions) if x == 0]]\n",
    "\n",
    "    add_plot = []\n",
    "    if not buy_signals.empty:\n",
    "        add_plot.append(mpf.make_addplot(buy_signals['Close'], type='scatter', marker='^', color='blue', markersize=100, label='Segnali Buy'))\n",
    "    if not sell_signals.empty:\n",
    "        add_plot.append(mpf.make_addplot(sell_signals['Close'], type='scatter', marker='v', color='magenta', markersize=100, label='Segnali Sell'))\n",
    "\n",
    "    add_plot.append(mpf.make_addplot(df_plot['Close'].iloc[-N_PREDICTIONS:], color='red', label='Prezzo di Chiusura'))\n",
    "\n",
    "    mpf.plot(df_plot, type='candle', style='charles', addplot=add_plot, title='Forecast',\n",
    "             ylabel='Prezzo', savefig=PLOT_FILE_PATH, volume=False, show_nontrading=False)\n",
    "\n",
    "    mpf.plot(df_plot, type='candle', style='charles', addplot=add_plot, title='Forecast',\n",
    "             ylabel='Prezzo', volume=False, show_nontrading=False)\n",
    "    mpf.show()\n",
    "\n",
    "def run_trading_model():\n",
    "    validate_predictions()\n",
    "    df = load_and_preprocess_data()\n",
    "    X = df[['Open', 'High', 'Low', 'Close', 'MA20', 'MA50', 'Volatility', 'RSI', 'MACD', 'Upper Bollinger', 'Lower Bollinger']].values\n",
    "    y = df['Target']\n",
    "\n",
    "    if os.path.exists(SCALER_PATH):\n",
    "        scaler = joblib.load(SCALER_PATH)\n",
    "    else:\n",
    "        scaler = MinMaxScaler()\n",
    "        scaler.fit(X)\n",
    "        joblib.dump(scaler, SCALER_PATH)\n",
    "    X_scaled = scaler.transform(X)\n",
    "\n",
    "    time_steps = 20\n",
    "    X_seq, y_seq = create_sequences(X_scaled, y.values, time_steps)\n",
    "    X_train, X_test = X_seq[:-N_PREDICTIONS], X_seq[-N_PREDICTIONS:]\n",
    "    y_train, y_test = y_seq[:-N_PREDICTIONS], y_seq[-N_PREDICTIONS:]\n",
    "\n",
    "    if os.path.exists(MODEL_PATH) and not REPEAT_TRAINING:\n",
    "        model = load_model(MODEL_PATH)\n",
    "    else:\n",
    "        model = Sequential([\n",
    "            LSTM(units=50, return_sequences=True, input_shape=(X_train.shape[1], X_train.shape[2])),\n",
    "            Dropout(0.2),\n",
    "            LSTM(units=50, return_sequences=False),\n",
    "            Dropout(0.2),\n",
    "            Dense(units=1, activation='sigmoid')\n",
    "        ])\n",
    "        model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "        early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "        model.fit(X_train, y_train, epochs=50, batch_size=32, validation_split=0.2, callbacks=[early_stopping])\n",
    "        model.save(MODEL_PATH)\n",
    "\n",
    "    predictions = (model.predict(X_test) > 0.5).astype(int)\n",
    "\n",
    "    results = []\n",
    "    for i, pred in enumerate(predictions.flatten()):\n",
    "        entry_price = round(df['Close'].iloc[-N_PREDICTIONS + i], 3)\n",
    "        order_type = \"Buy\" if pred == 1 else \"Sell\"\n",
    "        order_class = \"Limit\" if pred == 1 else \"Stop\"\n",
    "\n",
    "        stop_loss = round(entry_price * (0.98 if order_type == \"Buy\" else 1.02), 3)\n",
    "        take_profit = round(entry_price * (1 + MARGIN_PROFIT if order_type == \"Buy\" else 1 - MARGIN_PROFIT), 3)\n",
    "        \n",
    "        hypothetical_profit = calculator_profit(take_profit, entry_price)\n",
    "        hypothetical_loss = calculator_loss(stop_loss, entry_price)\n",
    "\n",
    "        data_obj = datetime.now()\n",
    "        data_utc = data_obj.replace(tzinfo=pytz.UTC)\n",
    "        data_utc = data_utc - timedelta(minutes=30)  # Sottraggo 30m per essere allineato al dataset\n",
    "        data_formatted = data_utc.strftime(\"%Y-%m-%d %H:%M:%S%z\")\n",
    "\n",
    "        results.append({\n",
    "            'Data Previsione': data_formatted,\n",
    "            'Tipo': f\"{order_type} {order_class}\",\n",
    "            'Prezzo': f\"{entry_price:.3f}\",\n",
    "            'Stop Loss': f\"{stop_loss:.3f}\",\n",
    "            'Take Profit': f\"{take_profit:.3f}\",\n",
    "            'Guadagno': f\"{hypothetical_profit:.2f}€\",\n",
    "            'Perdita': f\"{hypothetical_loss:.2f}€\"\n",
    "        })\n",
    "\n",
    "    results = sorted(results, key=lambda x: float(x['Prezzo']))\n",
    "\n",
    "    print(\"\\nPrevisioni Generate:\\n\")\n",
    "    row_index = 1\n",
    "    for result in results:\n",
    "        logging.info(f\"Data: {result['Data Previsione']}, Tipo: {result['Tipo']}, Prezzo: {result['Prezzo']}, Stop Loss: {result['Stop Loss']}, Take Profit: {result['Take Profit']}, Guadagno: {result['Guadagno']}, Perdita: {result['Perdita']}\")\n",
    "\n",
    "        type_colored = f\"\\033[94m{result['Tipo']}\\033[0m\" if result['Tipo'] == \"Buy\" or result['Tipo'] == \"Buy Limit\" or result['Tipo'] == \"Buy Stop\" else f\"\\033[91m{result['Tipo']}\\033[0m\"\n",
    "        entry_price_colored = f\"\\033[96m{result['Prezzo']}\\033[0m\"\n",
    "        stop_loss_colored = f\"\\033[93m{result['Stop Loss']}\\033[0m\"\n",
    "        take_profit_colored = f\"\\033[95m{result['Take Profit']}\\033[0m\"\n",
    "        guadagno_colored = f\"\\033[92m{result['Guadagno']}\\033[0m\" if float(result['Guadagno'][:-1]) > 0 else f\"\\033[91m{result['Guadagno']}\\033[0m\"\n",
    "        perdita_colored = f\"\\033[91m{result['Perdita']}\\033[0m\"\n",
    "\n",
    "        print(\n",
    "            f\"{row_index:>2})  {type_colored:<8} Prezzo: {entry_price_colored:<8} Stop Loss: {stop_loss_colored:<8} \"\n",
    "            f\"Take Profit: {take_profit_colored:<8} Guadagno: {guadagno_colored:<10} Perdita: {perdita_colored:<10}\"\n",
    "        )\n",
    "\n",
    "        row_index += 1\n",
    "\n",
    "    print(\"\\n\")\n",
    "    results_df = pd.DataFrame(results)\n",
    "    results_df = results_df[['Data Previsione', 'Tipo', 'Prezzo', 'Stop Loss', 'Take Profit', 'Guadagno', 'Perdita']]\n",
    "\n",
    "    if OVERWRITE_FORECAST_CSV:\n",
    "        results_df.to_csv(FORECAST_RESULTS_PATH, mode='w', index=False)\n",
    "    else:\n",
    "        if os.path.isfile(FORECAST_RESULTS_PATH):\n",
    "            results_df.to_csv(FORECAST_RESULTS_PATH, mode='a', index=False, header=False)\n",
    "        else:\n",
    "            results_df.to_csv(FORECAST_RESULTS_PATH, mode='w', index=False)\n",
    "\n",
    "    if GENERATE_PLOT:\n",
    "        plot_forex_candlestick(df, predictions)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    rate_exchange = exchange_currency(DATA_MODEL_RATE, FAVORITE_RATE)\n",
    "    if rate_exchange:\n",
    "        EXCHANGE_RATE = rate_exchange\n",
    "\n",
    "    run_trading_model()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
